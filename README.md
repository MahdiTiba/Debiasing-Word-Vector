# Debiasing-Word-Vector
Gender bias in word embeddings is a significant problem in Natural Language Processing tasks, which can reinforce harmful stereotypes.  This study  addresses gender bias in English word embeddings through a step-bystep approach, beginning with utilizing pre-trained FastText as a comprehensive word embedding, followed by data cleaning to remove meaningless words while preserving inherently gendered words. We then created a unit gender vector to measure the gender bias of each word, followed by debiasing the words by removing the gender dimension in vector space without impacting other dimensions. Meanwhile, inherently gendered words remained unchanged. In addition, to ensure balanced representation, pairs of gendered words were equalized symmetrically in terms of gender through an equalization step. The findings revealed a substantial decrease in gender bias, as the projection analyses showed that stereotypical words no longer had gender features following debiasing, but words with inherent gender meanings preserved their semantic stability.
